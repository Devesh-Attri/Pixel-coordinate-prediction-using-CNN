{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ef5c70",
   "metadata": {},
   "source": [
    "# **Step 1: Imports & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a8cdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07438b",
   "metadata": {},
   "source": [
    "# **Step 2: Dataset Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe8674fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 2500 images.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "IMG_SIZE = 50\n",
    "OUTPUT_DIR = \"dataset\"\n",
    "IMG_DIR = os.path.join(OUTPUT_DIR, \"images\")\n",
    "LABEL_FILE = os.path.join(OUTPUT_DIR, \"labels.csv\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "labels = []\n",
    "img_id = 0\n",
    "\n",
    "for y in range(IMG_SIZE):\n",
    "    for x in range(IMG_SIZE):\n",
    "        img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
    "        img[y, x] = 255\n",
    "\n",
    "        img_name = f\"img_{img_id:04d}.png\"\n",
    "        img_path = os.path.join(IMG_DIR, img_name)\n",
    "        cv2.imwrite(img_path, img)\n",
    "\n",
    "        labels.append([img_name, x, y])\n",
    "        img_id += 1\n",
    "\n",
    "with open(LABEL_FILE, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"image_name\", \"x\", \"y\"])\n",
    "    writer.writerows(labels)\n",
    "\n",
    "print(f\"Dataset created with {img_id} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2390c",
   "metadata": {},
   "source": [
    "# **Step 3: Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0929597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (2500, 50, 50, 1)\n",
      "Labels shape: (2500, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(img_dir, label_file):\n",
    "    images = []\n",
    "    heatmaps = []\n",
    "\n",
    "    with open(label_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            img_path = os.path.join(img_dir, row[\"image_name\"])\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "            heatmap = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n",
    "            heatmap[int(row[\"y\"]), int(row[\"x\"])] = 1.0\n",
    "            heatmap = np.expand_dims(heatmap, axis=-1)\n",
    "\n",
    "            images.append(img)\n",
    "            heatmaps.append(heatmap)\n",
    "\n",
    "    return np.array(images), np.array(heatmaps)\n",
    "\n",
    "\n",
    "X, Y = load_dataset(IMG_DIR, LABEL_FILE)\n",
    "\n",
    "print(\"Images shape:\", X.shape)\n",
    "print(\"Labels shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8ca2b",
   "metadata": {},
   "source": [
    "# **Step 4: Train / Val / Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "582d9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2000, 50, 50, 1)\n",
      "Val: (250, 50, 50, 1)\n",
      "Test: (250, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ff8c4",
   "metadata": {},
   "source": [
    "# **Step 5: Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "989551cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 50, 50, 16)        160       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 50, 50, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 50, 50, 1)         33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4833 (18.88 KB)\n",
      "Trainable params: 4833 (18.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(50, 50, 1)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"linear\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714aa84",
   "metadata": {},
   "source": [
    "# **Step 6: Compile & Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e796300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 6.2677e-04 - accuracy: 0.9996 - val_loss: 2.9672e-04 - val_accuracy: 0.9996\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 1.3011e-04 - accuracy: 1.0000 - val_loss: 1.5361e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 1.0838e-05 - accuracy: 1.0000 - val_loss: 1.1988e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 8.6685e-06 - accuracy: 1.0000 - val_loss: 9.9105e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 7.1824e-06 - accuracy: 1.0000 - val_loss: 7.6933e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.6031e-06 - accuracy: 1.0000 - val_loss: 5.5858e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 4.2507e-06 - accuracy: 1.0000 - val_loss: 4.1273e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.5576e-06 - accuracy: 1.0000 - val_loss: 3.5884e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 3.1969e-06 - accuracy: 1.0000 - val_loss: 3.1643e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 2.8467e-06 - accuracy: 1.0000 - val_loss: 2.7601e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.4763e-06 - accuracy: 1.0000 - val_loss: 2.3171e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 2.0938e-06 - accuracy: 1.0000 - val_loss: 1.8862e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.6994e-06 - accuracy: 1.0000 - val_loss: 1.4633e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.3112e-06 - accuracy: 1.0000 - val_loss: 1.0236e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 9.1939e-07 - accuracy: 1.0000 - val_loss: 5.3354e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=15,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd26afa",
   "metadata": {},
   "source": [
    "# **Step 7: Save Training Graphs (Loss + Accuracy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "968f5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training graphs saved.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.savefig(\"results/loss_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.savefig(\"results/accuracy_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Training graphs saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e654bef",
   "metadata": {},
   "source": [
    "# **Step 8: Evaluation on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cfad8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 7.4696e-07 - accuracy: 1.0000\n",
      "Test Loss: 0.000001\n",
      "Test Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {test_loss:.6f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420213a",
   "metadata": {},
   "source": [
    "# **Step 9: Coordinate Extraction (Argmax)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7914f980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "def extract_coordinates(heatmap):\n",
    "    idx = np.argmax(heatmap)\n",
    "    y, x = np.unravel_index(idx, (IMG_SIZE, IMG_SIZE))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "gt_coords = []\n",
    "pred_coords = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    gt_coords.append(extract_coordinates(Y_test[i]))\n",
    "    pred_coords.append(extract_coordinates(predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd659ade",
   "metadata": {},
   "source": [
    "# **Step 10: Ground Truth vs Prediction Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec66d986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions saved.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    img = X_test[i].squeeze()\n",
    "    gt_x, gt_y = gt_coords[i]\n",
    "    pr_x, pr_y = pred_coords[i]\n",
    "\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.scatter(gt_x, gt_y, c=\"green\", label=\"Ground Truth\")\n",
    "    plt.scatter(pr_x, pr_y, c=\"red\", marker=\"x\", label=\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"GT: ({gt_x},{gt_y}) | Pred: ({pr_x},{pr_y})\")\n",
    "    plt.savefig(f\"results/sample_{i}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Sample predictions saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec42268",
   "metadata": {},
   "source": [
    "# **Step 11: Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b4844a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deveshattri/Desktop/Internship Tasks/Deepedge/.venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"pixel_locator_model.h5\")\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
